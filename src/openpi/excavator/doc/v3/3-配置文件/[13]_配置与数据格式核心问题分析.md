# 配置与数据格式核心问题分析

## 问题概述

在推理实现过程中发现，我们对 **droid_policy.py** 和 **config.py** 的配置存在问题，这些问题的根源在于对数据集格式的理解不足。本文档总结了关键问题和解决方案。

---

## 问题 1：图像字段名称（"main" vs 其他名称）

### 数据集实际格式（meta/info.json）

```json
{
  "features": {
    "main": {
      "dtype": "video",
      "shape": [480, 640, 3],
      "info": {
        "video.height": 480,
        "video.width": 640,
        "video.channels": 3
      }
    }
  }
}
```

**关键发现**：数据集中的视频图像字段名称是 **"main"**，不是通用的 "image"。

### 配置文件的处理（正确做法）

在 **droid_policy.py** 中的 `ExcavatorInputs` 类（第 114-125 行）：

```python
# 尝试多个可能的键：优先级顺序
for key in ["image", "main", "observation/image"]:
    if key in data:
        image = _parse_image(data[key])
        break
if image is None:
    raise ValueError(f"Could not find image key in data. Available keys: {list(data.keys())}")
```

✅ **这个处理是正确的** —— 它能够兼容多种字段名称，包括 "main"。

### 推理时的对应关系

在 **test_infer_v3.py** 中正确使用了 "main"：

```python
video_path = data_dir / "videos" / "chunk-000" / "main" / "episode_000000.mp4"
```

✅ **路径是正确的**。

---

## 问题 2：数据对齐问题（frame_index 的重要性）

### 数据集结构（meta/info.json）

```json
{
  "total_frames": 3233,
  "total_episodes": 1,
  "fps": 10,
  "features": {
    "frame_index": {
      "dtype": "int64",
      "shape": [1]
    }
  }
}
```

### 关键问题

- **视频总帧数**: 3233 帧
- **Parquet 样本数**: 约 1300 样本
- **比例**: 3233 / 1300 ≈ 2.5，不是精确的 3:1 关系

### 错误做法（V4 中的问题）

```python
# ❌ 错误：直接用索引对应
for i in range(len(states)):
    obs = {
        "state": states[i],
        "image": processed_images[i]  # 假设 processed_images 和 states 一一对应
    }
```

**问题**：
- 视频帧数 > 样本数，不能简单地用索引对应
- 会导致帧索引越界或使用错误的帧

### 正确做法（修复后的 V3）

```python
# ✅ 正确：使用 frame_index 字段
frame_indices = df['frame_index'].values.astype(np.int32)

for i in range(len(states)):
    frame_idx = int(frame_indices[i])  # 获取该样本对应的帧索引
    if frame_idx >= len(video_frames):
        frame_idx = len(video_frames) - 1

    image = video_frames[frame_idx]  # 使用正确的帧索引
    obs = create_observation_dict(states[i], image)
```

✅ **这确保了 state 和图像帧的正确对应**

---

## 问题 3：Prompt 字段的错误使用

### 数据集不包含 Prompt

在 parquet 和 video 元数据中**没有 prompt 字段**。这意味着：
- 模型训练时**没有**使用文本驱动
- 推理时不应该构造虚拟的 prompt

### 错误做法（V3 原始版本）

```python
# ❌ 错误：添加了不存在的 prompt 字段
obs = {
    "state": state,
    "image": dummy_image,
    "prompt": "predict excavator joint action from joint state"  # ❌ 错误
}
```

### 正确做法（修复后的 V3）

```python
# ✅ 正确：不添加 prompt 字段
obs = {
    "state": state,
    "image": image,
}
# 让 ExcavatorInputs 在需要时注入默认 prompt
```

---

## 问题 4：虚拟图像 vs 真实图像

### 数据集格式

数据集提供了真实的视频帧数据，位置：
```
videos/chunk-000/main/episode_000000.mp4
```

### 错误做法（V3 原始版本）

```python
# ❌ 错误：使用虚拟图像
dummy_image = np.zeros((224, 224, 3), dtype=np.uint8)
obs = {
    "state": state,
    "image": dummy_image,  # 全黑图像
    "prompt": "..."
}
```

**问题**：
- 模型在训练时使用真实视频帧
- 推理时给它全黑图像，分布偏差太大
- 模型性能严重下降

### 正确做法（修复后的 V3）

```python
# ✅ 正确：加载真实视频帧
mp4reader = MP4Reader(filepath=str(video_path), resolution=(224, 224), ...)
video_frames = mp4reader.read_all_frames()

# 推理时使用真实帧
frame_idx = int(frame_indices[i])
image = video_frames[frame_idx]
```

---

## 总结表格

| 问题 | 原始（V3） | 修复后（V3+） | 根源 |
|------|----------|------------|------|
| **图像字段名** | 不明确 | "main"（位于 meta/info.json） | 数据集配置 |
| **图像来源** | 虚拟（全黑） | 真实视频帧 | 应与训练数据保持一致 |
| **Prompt 字段** | 手动添加 | 由模型处理 | 模型无需文本驱动 |
| **帧对应方式** | 直接索引 | frame_index 字段 | parquet 中的显式字段 |

---

## 推荐配置流程

### 1. 验证数据集格式

```python
# 读取元数据
import json
with open("meta/info.json") as f:
    meta = json.load(f)

print(f"视频字段名: {list(meta['features'].keys())}")
print(f"总帧数: {meta['total_frames']}")
print(f"总样本数: {meta对应 parquet 行数}")
```

### 2. 确认 Parquet 中的必要列

```python
import pandas as pd
df = pd.read_parquet("data/chunk-000/episode_000000.parquet")

required_cols = {"state", "action", "timestamp", "frame_index"}
assert required_cols.issubset(df.columns), f"缺少必要列: {required_cols - set(df.columns)}"
```

### 3. 在推理脚本中

```python
# 加载数据时
frame_indices = df['frame_index'].values

# 推理时
for i in range(len(states)):
    frame_idx = int(frame_indices[i])
    image = video_frames[frame_idx]
    obs = {"state": states[i], "image": image}
    result = policy.infer(obs)
```

---

## 对 config.py 的影响

在 **config.py** 中的 `DataConfig` 类中，应该有清晰的注释说明：

```python
@dataclasses.dataclass(frozen=True)
class DataConfig:
    """
    数据配置

    关键说明：
    1. 图像字段名在数据集中可能不同（"image", "main", "observation/image"）
       -> droid_policy.ExcavatorInputs 已处理兼容性

    2. 时序对应由 frame_index 字段驱动（不是简单的线性对应）
       -> 推理时必须使用 frame_index

    3. 不使用 prompt 文本驱动
       -> 如需要，让模型的 model_transforms 注入默认 prompt
    """
```

---

## 对 droid_policy.py 的评价

✅ **ExcavatorInputs 类是正确的**：
- 正确处理了多种图像字段名称
- 支持真实图像数据
- 正确提取了 4 维状态（excavator 特定）

⚠️ **建议改进**：
- 在代码注释中明确说明 "main" 是标准字段名
- 添加数据集格式文档引用

---

## 关键要点

1. **"main" 是数据集约定** → 位于 meta/info.json 的 features 中
2. **frame_index 是必须的** → 确保 state 和图像正确对应
3. **不使用 prompt 驱动** → 模型已在 model_transforms 中处理
4. **真实图像很重要** → 与训练数据分布一致是关键
5. **兼容性优先** → droid_policy.py 的多键查找是正确的设计
