#!/usr/bin/env python3
"""
æŒ–æ˜æœºæ¨ç†ç³»ç»Ÿ - å¿«é€Ÿè¯Šæ–­è„šæœ¬

ä½¿ç”¨æ–¹æ³•ï¼š
  python3 quick_diagnosis.py

è¯¥è„šæœ¬ä¼šè‡ªåŠ¨æ‰§è¡Œæ‰€æœ‰è¯Šæ–­æ­¥éª¤ï¼Œå¹¶ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šã€‚
"""

import json
import numpy as np
import pandas as pd
from pathlib import Path
import sys
from datetime import datetime

class QuickDiagnosis:
    def __init__(self):
        self.report = {
            'timestamp': datetime.now().isoformat(),
            'findings': {},
            'recommendations': [],
            'severity': 'unknown'
        }
        self.output_dir = Path("/home/er/Code/openpi-v1/output_v3")
        self.log_dir = Path("/home/er/Code/openpi-v1/logs")
        self.log_dir.mkdir(exist_ok=True)

    def log(self, msg: str, level: str = "INFO"):
        """æ‰“å°å¹¶è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        prefix = {
            "INFO": "â„¹ï¸ ",
            "SUCCESS": "âœ…",
            "WARNING": "âš ï¸ ",
            "ERROR": "âŒ",
            "DEBUG": "ğŸ”"
        }.get(level, "â†’ ")

        full_msg = f"{prefix} [{timestamp}] {msg}"
        print(full_msg)

    def check_output_exists(self) -> bool:
        """æ£€æŸ¥ output_v3 æ˜¯å¦å­˜åœ¨"""
        self.log("æ£€æŸ¥ output_v3 ç›®å½•...", "DEBUG")

        if not self.output_dir.exists():
            self.log(f"output_v3 ä¸å­˜åœ¨: {self.output_dir}", "ERROR")
            self.log("è¯·å…ˆè¿è¡Œæ¨ç†è„šæœ¬ï¼šuv run openpi/src/openpi/excavator/test_infer_v3.py", "WARNING")
            return False

        required_files = [
            "v3_stats.json",
            "v3_predictions.csv",
            "v3_1_time_series.png",
            "v3_2_error_analysis.png"
        ]

        for file in required_files:
            if not (self.output_dir / file).exists():
                self.log(f"ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {file}", "WARNING")

        self.log("âœ… output_v3 å­˜åœ¨å¹¶åŒ…å«å¿…éœ€çš„è¾“å‡ºæ–‡ä»¶", "SUCCESS")
        return True

    def analyze_performance(self):
        """åˆ†ææ¨ç†æ€§èƒ½"""
        self.log("åˆ†ææ¨ç†æ€§èƒ½...", "DEBUG")

        stats_file = self.output_dir / "v3_stats.json"
        with open(stats_file) as f:
            stats = json.load(f)

        mae = np.array(stats['MAE'])
        rmse = np.array(stats['RMSE'])

        self.report['findings']['performance'] = {
            'total_samples': stats['æ€»æ ·æœ¬æ•°'],
            'valid_samples': stats['æœ‰æ•ˆæ ·æœ¬æ•°'],
            'invalid_samples': stats['æ— æ•ˆæ ·æœ¬æ•°'],
            'success_rate': stats['æœ‰æ•ˆæ ·æœ¬æ•°'] / stats['æ€»æ ·æœ¬æ•°'] * 100,
            'mae': mae.tolist(),
            'rmse': rmse.tolist(),
            'mae_mean': float(np.mean(mae)),
            'rmse_mean': float(np.mean(rmse))
        }

        self.log(f"æˆåŠŸç‡: {stats['æœ‰æ•ˆæ ·æœ¬æ•°']}/{stats['æ€»æ ·æœ¬æ•°']} ({stats['æœ‰æ•ˆæ ·æœ¬æ•°']/stats['æ€»æ ·æœ¬æ•°']*100:.1f}%)", "INFO")
        self.log(f"å¹³å‡ MAE: {np.mean(mae):.6f} rad", "INFO")
        self.log(f"å¹³å‡ RMSE: {np.mean(rmse):.6f} rad", "INFO")

        # è¯„çº§
        if np.mean(mae) < 0.05:
            rating = "ä¼˜ç§€"
            self.report['severity'] = "green"
        elif np.mean(mae) < 0.1:
            rating = "å¾ˆå¥½"
            self.report['severity'] = "yellow"
        elif np.mean(mae) < 0.15:
            rating = "è‰¯å¥½"
            self.report['severity'] = "yellow"
        elif np.mean(mae) < 0.2:
            rating = "å¯æ¥å—"
            self.report['severity'] = "orange"
        else:
            rating = "å·®"
            self.report['severity'] = "red"

        self.log(f"æ€§èƒ½è¯„çº§: {rating}", "INFO" if np.mean(mae) < 0.15 else "WARNING")

    def analyze_data_distribution(self):
        """åˆ†ææ•°æ®åˆ†å¸ƒ"""
        self.log("åˆ†ææ•°æ®åˆ†å¸ƒ...", "DEBUG")

        try:
            train_path = Path("/root/gpufree-data/lerobot_examples_490_train/data/chunk-000/episode_000000.parquet")
            test_path = Path("/root/gpufree-data/lerobot_examples_490_test/data/chunk-000/episode_000000.parquet")

            if not train_path.exists() or not test_path.exists():
                self.log("æ— æ³•è®¿é—®æ•°æ®é›†æ–‡ä»¶", "WARNING")
                return

            df_train = pd.read_parquet(train_path)
            df_test = pd.read_parquet(test_path)

            states_train = np.array([np.array(s) for s in df_train['state'].tolist()])
            states_test = np.array([np.array(s) for s in df_test['state'].tolist()])

            # æ£€æŸ¥èŒƒå›´åŒ¹é…
            train_min, train_max = states_train.min(axis=0), states_train.max(axis=0)
            test_min, test_max = states_test.min(axis=0), states_test.max(axis=0)

            out_of_range = np.sum((states_test < train_min) | (states_test > train_max))
            out_of_range_pct = out_of_range / states_test.size * 100

            self.report['findings']['data_distribution'] = {
                'train_shape': states_train.shape,
                'test_shape': states_test.shape,
                'out_of_range_samples': int(out_of_range),
                'out_of_range_percentage': float(out_of_range_pct)
            }

            self.log(f"è®­ç»ƒæ•°æ®èŒƒå›´: {train_min} ~ {train_max}", "DEBUG")
            self.log(f"æµ‹è¯•æ•°æ®èŒƒå›´: {test_min} ~ {test_max}", "DEBUG")

            if out_of_range_pct > 5:
                self.log(f"âš ï¸ {out_of_range_pct:.1f}% çš„æµ‹è¯•æ•°æ®è¶…å‡ºè®­ç»ƒèŒƒå›´", "WARNING")
                self.report['recommendations'].append("æ•°æ®åˆ†å¸ƒä¸åŒ¹é…ï¼šæ‰©å¤§è®­ç»ƒæ•°æ®æˆ–é‡æ–°æ”¶é›†æ•°æ®")
            else:
                self.log(f"âœ… æ•°æ®åˆ†å¸ƒåŒ¹é…ï¼š{out_of_range_pct:.1f}% è¶…å‡ºèŒƒå›´", "SUCCESS")

        except Exception as e:
            self.log(f"æ•°æ®åˆ†æå¤±è´¥: {e}", "WARNING")

    def analyze_predictions(self):
        """åˆ†æé¢„æµ‹ç»“æœ"""
        self.log("åˆ†æé¢„æµ‹ç»“æœ...", "DEBUG")

        try:
            df = pd.read_csv(self.output_dir / "v3_predictions.csv")

            # æ£€æŸ¥ç³»ç»Ÿæ€§åå·®
            bias_detected = False
            for i in range(4):
                true_col = f'true_J{i+1}'
                pred_col = f'pred_J{i+1}'

                if true_col in df.columns and pred_col in df.columns:
                    error = df[true_col] - df[pred_col]
                    bias = np.mean(error.dropna())

                    if abs(bias) > 0.05:
                        self.log(f"âš ï¸ å…³èŠ‚{i+1}å­˜åœ¨ç³»ç»Ÿæ€§åå·®: {bias:.6f}", "WARNING")
                        bias_detected = True

            if not bias_detected:
                self.log("âœ… æ²¡æœ‰å‘ç°ç³»ç»Ÿæ€§åå·®", "SUCCESS")

            self.report['findings']['prediction_quality'] = {
                'bias_detected': bias_detected
            }

        except Exception as e:
            self.log(f"é¢„æµ‹åˆ†æå¤±è´¥: {e}", "WARNING")

    def check_training_logs(self):
        """æ£€æŸ¥è®­ç»ƒæ—¥å¿—"""
        self.log("æ£€æŸ¥è®­ç»ƒæ—¥å¿—...", "DEBUG")

        try:
            checkpoint_dir = Path("/root/gpufree-data/checkpoints/pi05_excavator_finetune/excavator_v1")
            checkpoints = sorted([d for d in checkpoint_dir.iterdir() if d.is_dir()],
                                key=lambda x: int(x.name))

            self.log(f"æ‰¾åˆ° {len(checkpoints)} ä¸ª checkpoints", "INFO")
            self.log(f"æœ€ç»ˆ checkpoint: step {checkpoints[-1].name}", "INFO")

            # æ£€æŸ¥æ˜¯å¦æœ‰æ—¥å¿—
            log_files = list(checkpoint_dir.glob("*.log")) + \
                       list(checkpoint_dir.parent.glob("*.log"))

            if log_files:
                self.log(f"âœ… æ‰¾åˆ° {len(log_files)} ä¸ªè®­ç»ƒæ—¥å¿—æ–‡ä»¶", "SUCCESS")
                self.report['findings']['training'] = {
                    'log_files_count': len(log_files),
                    'status': 'logs_available'
                }
            else:
                self.log("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—æ–‡ä»¶", "WARNING")
                self.report['recommendations'].append("æ·»åŠ è®­ç»ƒæ—¥å¿—ä»¥ä¾¿åç»­è¯Šæ–­ï¼šä¿®æ”¹è®­ç»ƒè„šæœ¬ä¿å­˜ loss æ›²çº¿")
                self.report['findings']['training'] = {
                    'log_files_count': 0,
                    'status': 'no_logs'
                }

        except Exception as e:
            self.log(f"æ—¥å¿—æ£€æŸ¥å¤±è´¥: {e}", "WARNING")

    def generate_diagnosis(self):
        """ç”Ÿæˆè¯Šæ–­ç»“è®º"""
        self.log("\n" + "="*70, "INFO")
        self.log("è¯Šæ–­ç»“è®º", "INFO")
        self.log("="*70, "INFO")

        mae = self.report['findings']['performance']['mae_mean']

        if mae < 0.05:
            diagnosis = "âœ… æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼Œæ¨ç†æ•ˆæœå¾ˆå¥½"
            root_cause = "æ— ä¸¥é‡é—®é¢˜"
        elif mae < 0.1:
            diagnosis = "âœ… æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œæ¨ç†åŸºæœ¬æ­£å¸¸"
            root_cause = "å¯èƒ½å­˜åœ¨å¾®å°çš„æ•°æ®æˆ–é…ç½®é—®é¢˜"
        elif mae < 0.15:
            diagnosis = "âš ï¸ æ¨¡å‹è¡¨ç°ä¸€èˆ¬ï¼Œå­˜åœ¨å¯æ”¹è¿›ç©ºé—´"
            if 'data_distribution' in self.report['findings']:
                if self.report['findings']['data_distribution']['out_of_range_percentage'] > 5:
                    root_cause = "ä¸»è¦åŸå› ï¼šæ•°æ®åˆ†å¸ƒä¸åŒ¹é…"
                else:
                    root_cause = "ä¸»è¦åŸå› ï¼šå¾®è°ƒæ¨¡å‹å¯èƒ½ä¸å¤Ÿå¥½æˆ–é…ç½®ä¸ä¼˜"
            else:
                root_cause = "åŸå› ä¸ç¡®å®šï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥"
        else:
            diagnosis = "âŒ æ¨¡å‹è¡¨ç°å·®ï¼Œå­˜åœ¨ä¸¥é‡é—®é¢˜"
            if 'data_distribution' in self.report['findings']:
                if self.report['findings']['data_distribution']['out_of_range_percentage'] > 20:
                    root_cause = "æ ¹æœ¬åŸå› ï¼šæ•°æ®ä¸¥é‡ä¸åŒ¹é…"
                else:
                    root_cause = "æ ¹æœ¬åŸå› ï¼šå¾®è°ƒé—®é¢˜ï¼ˆæ¨¡å‹æœªæ”¶æ•›æˆ–é…ç½®é”™è¯¯ï¼‰"
            else:
                root_cause = "æ ¹æœ¬åŸå› ä¸ç¡®å®šï¼Œéœ€è¦æ£€æŸ¥è®­ç»ƒæ—¥å¿—"

        self.log(diagnosis, "INFO")
        self.log(f"æ ¹æœ¬åŸå› : {root_cause}", "INFO")

        self.log("\nå»ºè®®è¡ŒåŠ¨:", "INFO")
        for i, rec in enumerate(self.report['recommendations'], 1):
            self.log(f"  {i}. {rec}", "INFO")

        return root_cause

    def save_report(self):
        """ä¿å­˜è¯Šæ–­æŠ¥å‘Š"""
        report_file = self.log_dir / f"diagnosis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        with open(report_file, 'w') as f:
            json.dump(self.report, f, indent=2, ensure_ascii=False)

        self.log(f"è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {report_file}", "SUCCESS")

    def run(self):
        """æ‰§è¡Œå®Œæ•´è¯Šæ–­"""
        self.log("="*70, "INFO")
        self.log("æŒ–æ˜æœºæ¨ç†ç³»ç»Ÿ - å¿«é€Ÿè¯Šæ–­", "INFO")
        self.log("="*70, "INFO")

        # Step 1: æ£€æŸ¥è¾“å‡º
        if not self.check_output_exists():
            self.log("\næ— æ³•è¿›è¡Œè¯Šæ–­ï¼Œè¯·å…ˆè¿è¡Œæ¨ç†è„šæœ¬", "ERROR")
            return

        self.log("", "INFO")

        # Step 2: åˆ†ææ€§èƒ½
        self.analyze_performance()
        self.log("", "INFO")

        # Step 3: åˆ†ææ•°æ®åˆ†å¸ƒ
        self.analyze_data_distribution()
        self.log("", "INFO")

        # Step 4: åˆ†æé¢„æµ‹è´¨é‡
        self.analyze_predictions()
        self.log("", "INFO")

        # Step 5: æ£€æŸ¥è®­ç»ƒæ—¥å¿—
        self.check_training_logs()
        self.log("", "INFO")

        # Step 6: ç”Ÿæˆè¯Šæ–­
        root_cause = self.generate_diagnosis()

        # Step 7: ä¿å­˜æŠ¥å‘Š
        self.log("", "INFO")
        self.save_report()

        self.log("\n" + "="*70, "INFO")
        self.log("è¯Šæ–­å®Œæˆ", "SUCCESS")
        self.log("="*70, "INFO")
        self.log("\nä¸‹ä¸€æ­¥ï¼š", "INFO")
        self.log("  â€¢ æŸ¥çœ‹å®Œæ•´çš„è¯Šæ–­æŒ‡å—ï¼šdoc/v3/[8] å®Œæ•´è¯Šæ–­æŒ‡å—.md", "INFO")
        self.log("  â€¢ æ ¹æ®è¯Šæ–­ç»“æœæ‰§è¡Œç›¸åº”çš„ä¿®å¤æ­¥éª¤", "INFO")


if __name__ == "__main__":
    try:
        diagnosis = QuickDiagnosis()
        diagnosis.run()
    except KeyboardInterrupt:
        print("\nè¯Šæ–­è¢«ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nè¯Šæ–­è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
