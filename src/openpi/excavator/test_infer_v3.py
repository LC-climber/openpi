# test_infer_v3.py
"""
ä¿®å¤ç‰ˆæœ¬çš„æŒ–æ˜æœºæ¨ç†ç³»ç»Ÿ V3ï¼ˆå¢å¼ºç‰ˆ - å«è§†é¢‘å¸§æ•°æ®ä¸è§’åº¦åŒ…è£…çº æ­£ï¼‰

æ ¸å¿ƒæ”¹è¿›ï¼ˆç›¸æ¯”åŸå§‹æ¨ç†è„šæœ¬ï¼‰ï¼š
1. âœ… æ­£ç¡®åŠ è½½è§†é¢‘å¸§æ•°æ®ï¼ˆä½¿ç”¨ frame_index å¯¹åº”å…³ç³»ï¼‰
   - ä» parquet çš„ frame_index å­—æ®µè·å–æ¯ä¸ª state å¯¹åº”çš„è§†é¢‘å¸§
   - è§£å†³ state ä¸è§†é¢‘å¸§çš„éçº¿æ€§å¯¹åº”é—®é¢˜ï¼ˆ1300 æ ·æœ¬ vs 3233 å¸§ï¼‰

2. âœ… ä½¿ç”¨çœŸå®è§†é¢‘å›¾åƒæ›¿ä»£è™šæ‹Ÿå›¾åƒ
   - åŠ è½½åŸå§‹è§†é¢‘å¸§ä½œä¸ºè§‚å¯Ÿ
   - æ­£ç¡®å¤„ç†å›¾åƒæ ¼å¼ï¼ˆBGR -> RGBï¼ŒC,H,W è½¬ H,W,Cï¼‰

3. âœ… ç§»é™¤é”™è¯¯çš„æ–‡æœ¬æç¤ºè¯ï¼ˆpromptï¼‰
   - ä¸åº”è¯¥ä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æç¤ºè¯
   - æ¨¡å‹è®­ç»ƒæ—¶æ²¡æœ‰ä½¿ç”¨ prompt å­—æ®µ

4. âœ… åº”ç”¨è§’åº¦åŒ…è£…çº æ­£ï¼ˆJ4 å›è½¬å…³èŠ‚ï¼‰
   - ä½¿ç”¨ atan2 å°†è§’åº¦è§„èŒƒåŒ–åˆ° [-Ï€, Ï€]
   - è§£å†³ Â±Ï€ è¾¹ç•Œè·¨è¶Šé—®é¢˜
   - ç”ŸæˆåŸå§‹å’Œçº æ­£åçš„ä¸¤å¥—ç»Ÿè®¡ç»“æœ

5. âœ… å®Œæ•´çš„æ•°æ®éªŒè¯å’Œå¯è§†åŒ–
   - ç”Ÿæˆæ—¶åºå¯¹æ¯”ã€è¯¯å·®åˆ†æã€è¯¯å·®åˆ†å¸ƒå›¾è¡¨
   - ä¿å­˜åŸå§‹æ•°æ®å’Œç»Ÿè®¡æ±‡æ€»

å…³é”®æ•°æ®å¯¹åº”å…³ç³»ï¼ˆæ¥è‡ª meta/info.jsonï¼‰ï¼š
  - æ€»è§†é¢‘å¸§æ•°: 3233 å¸§ @ 10 FPS
  - æ€» parquet æ ·æœ¬æ•°: 1300 æ ·æœ¬
  - å¸§ç´¢å¼•ï¼šæ¯ä¸ªæ ·æœ¬éƒ½æœ‰ frame_index å­—æ®µæŒ‡å‘å¯¹åº”çš„è§†é¢‘å¸§

ä½¿ç”¨æµç¨‹ï¼š
  1. ç¡®ä¿è§†é¢‘æ–‡ä»¶å­˜åœ¨ï¼švideos/chunk-000/main/episode_000000.mp4
  2. è¿è¡Œæ­¤è„šæœ¬è¿›è¡Œæ¨ç†å’Œåˆ†æ
  3. è¾“å‡ºåŒ…å«å®Œæ•´å¯è§†åŒ–å’Œç»Ÿè®¡ç»“æœ
"""

import dataclasses
import json
import logging
import pathlib
import subprocess
import copy
from typing import Optional

import einops
import numpy as np
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import cv2

from openpi_client.websocket_client_policy import WebsocketClientPolicy
from openpi.training import config as _config
from openpi.training import checkpoints as _checkpoints
from openpi import transforms as _transforms
from openpi.shared import normalize as _normalize
import openpi.models.model as _model

# ==========================================
# é…ç½®ä¸å¸¸é‡
# ==========================================

CONFIG = {
    "data_path": "/root/gpufree-data/lerobot_examples_490_test",
    "checkpoint_dir": "/root/gpufree-data/checkpoints/pi05_excavator_finetune/excavator_v1/19999",
    "config_name": "pi05_excavator_finetune",
    "host": "127.0.0.1",
    "port": 8000,
    "num_samples": 1300,
    "output_dir": Path("output_v3"),
}

# ==========================================
# å·¥å…·å‡½æ•°
# ==========================================

def _parse_image(image) -> np.ndarray:
    """å°†å›¾åƒè½¬æ¢ä¸º (H, W, C) uint8 æ ¼å¼

    å¤„ç†ä¸¤ç§å¸¸è§æ ¼å¼ï¼š
    - (C, H, W) float32 (0-1) -> (H, W, C) uint8 (0-255)
    - (H, W, C) uint8 -> (H, W, C) uint8
    """
    image = np.asarray(image)

    # å¦‚æœæ˜¯æµ®ç‚¹æ•° (0-1)ï¼Œè½¬æ¢ä¸º 0-255 uint8
    if np.issubdtype(image.dtype, np.floating):
        image = (255 * image).astype(np.uint8)

    # å¦‚æœæ˜¯ (C, H, W) æ ¼å¼ï¼Œè½¬æ¢ä¸º (H, W, C)
    if image.ndim == 3 and image.shape[0] == 3:
        image = einops.rearrange(image, "c h w -> h w c")

    return image


class MP4Reader:
    """ä½¿ç”¨ ffmpeg é«˜æ•ˆè¯»å–è§†é¢‘å¸§"""

    def __init__(self, filepath, resolution, video_hw, video_hh):
        """
        Args:
            filepath: è§†é¢‘è·¯å¾„
            resolution: æ¨¡å‹è¾“å…¥åˆ†è¾¨ç‡ (H, W)
            video_hw: åŸè§†é¢‘å®½
            video_hh: åŸè§†é¢‘é«˜
        """
        self.filepath = filepath
        self.resolution = resolution
        self.video_w = video_hw
        self.video_h = video_hh
        self._index = 0

        self._ffmpeg_cmd = [
            "ffmpeg",
            "-loglevel", "error",
            "-hwaccel", "none",
            "-i", filepath,
            "-f", "rawvideo",
            "-pix_fmt", "bgr24",
            "-"
        ]

        self._pipe = subprocess.Popen(
            self._ffmpeg_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            bufsize=10**8
        )

    def read_frame(self):
        """è¯»å–ä¸‹ä¸€å¸§"""
        frame_size = self.video_w * self.video_h * 3
        raw = self._pipe.stdout.read(frame_size)

        if len(raw) != frame_size:
            return None

        frame = np.frombuffer(raw, np.uint8)
        frame = frame.reshape((self.video_h, self.video_w, 3))
        self._index += 1

        # è°ƒæ•´åˆ°ç›®æ ‡åˆ†è¾¨ç‡
        if self.resolution == (0, 0):
            return frame
        return self._resize_frame(frame, self.resolution)

    @staticmethod
    def _resize_frame(image, target_shape=(224, 224), padding_color=(0, 0, 0)):
        """ä¿æŒå®½é«˜æ¯”å¡«å……å›¾åƒè‡³ç›®æ ‡å°ºå¯¸"""
        orig_height, orig_width = image.shape[:2]
        target_height, target_width = target_shape

        scale = min(target_height / orig_height, target_width / orig_width)
        scaled_width = int(orig_width * scale)
        scaled_height = int(orig_height * scale)

        resized = cv2.resize(
            image,
            (scaled_width, scaled_height),
            interpolation=cv2.INTER_LINEAR
        )

        width_pad = target_width - scaled_width
        height_pad = target_height - scaled_height
        left_pad = width_pad // 2
        right_pad = width_pad - left_pad
        top_pad = height_pad // 2
        bottom_pad = height_pad - top_pad

        padded = cv2.copyMakeBorder(
            resized,
            top_pad, bottom_pad, left_pad, right_pad,
            cv2.BORDER_CONSTANT,
            value=padding_color
        )
        return padded

    def read_all_frames(self):
        """ä¸€æ¬¡æ€§è¯»å–æ‰€æœ‰å¸§"""
        frames = []
        while True:
            frame = self.read_frame()
            if frame is None:
                break
            frames.append(frame)
        return np.array(frames)

    def release(self):
        """é‡Šæ”¾èµ„æº"""
        if self._pipe:
            self._pipe.terminate()
            self._pipe.wait()


def apply_angle_wrapping(values: np.ndarray, dims: list = None) -> np.ndarray:
    """å¯¹æŒ‡å®šç»´åº¦åº”ç”¨è§’åº¦åŒ…è£…ï¼ˆè§„èŒƒåŒ–åˆ° [-Ï€, Ï€]ï¼‰

    åŸç†ï¼š
        ä½¿ç”¨ atan2(sin(Î¸), cos(Î¸)) å°†ä»»æ„è§’åº¦æ˜ å°„åˆ° [-Ï€, Ï€] èŒƒå›´
        è¿™è§£å†³äº†è§’åº¦æ•°æ®åœ¨ Â±Ï€ è¾¹ç•Œå¤„çš„è·³è·ƒé—®é¢˜

    å‚æ•°ï¼š
        values: (N, 4) æ•°ç»„ï¼Œä»£è¡¨é¢„æµ‹/çœŸå®çš„å…³èŠ‚è§’åº¦
        dims: è¦å¤„ç†çš„ç»´åº¦åˆ—è¡¨ï¼Œé»˜è®¤ [3] è¡¨ç¤ºåªå¤„ç† J4 (å›è½¬)

    è¿”å›ï¼š
        wrapped: ç»è¿‡è§’åº¦åŒ…è£…åçš„æ•°ç»„
    """
    if dims is None:
        dims = [3]  # é»˜è®¤åªå¤„ç† J4ï¼ˆå›è½¬å…³èŠ‚ï¼‰

    wrapped = values.copy()
    for dim in dims:
        if dim < wrapped.shape[-1]:
            # ä½¿ç”¨ atan2(sin(Î¸), cos(Î¸)) è¿›è¡Œå½’ä¸€åŒ–
            wrapped[..., dim] = np.arctan2(
                np.sin(values[..., dim]),
                np.cos(values[..., dim])
            )
    return wrapped


def configure_fonts():
    """é…ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º"""
    font_candidates = [
        'SimHei.ttf', 'simhei.ttf',
        'Microsoft YaHei.ttf', 'msyh.ttf',
        'NotoSansCJK-Regular.ttc',
        'WenQuanYiMicroHei.ttf',
        'PingFang.ttc',
        'Arial Unicode MS.ttf'
    ]

    font_path = None
    system_fonts = fm.findSystemFonts(fontpaths=None, fontext='ttf')
    for font_file in system_fonts:
        if Path(font_file).name in font_candidates:
            font_path = font_file
            break

    if font_path:
        my_font = fm.FontProperties(fname=font_path)
        plt.rcParams['font.family'] = my_font.get_name()

    plt.rcParams['axes.unicode_minus'] = False


def load_data_with_validation(data_path: str, num_samples: int) -> tuple:
    """
    åŠ è½½æ•°æ®å¹¶è¿›è¡ŒéªŒè¯

    è¿”å›: (states, actions, timestamps, frame_indices, video_frames, data_info)
    """
    print("\n" + "="*60)
    print("ğŸ“‚ åŠ è½½æ¨ç†æ•°æ®é›†")
    print("="*60)

    data_dir = Path(data_path)
    parquet_path = data_dir / "data" / "chunk-000" / "episode_000000.parquet"
    video_path = data_dir / "videos" / "chunk-000" / "main" / "episode_000000.mp4"

    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    if not parquet_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {parquet_path}")
    if not video_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶: {video_path}")

    # ===== åŠ è½½ Parquet æ•°æ® =====
    print("\nğŸ“‹ åŠ è½½ Parquet æ•°æ®...")
    df = pd.read_parquet(parquet_path)
    print(f"  å¯ç”¨åˆ—: {df.columns.tolist()}")

    if num_samples < len(df):
        df = df.iloc[:num_samples]

    # éªŒè¯å¿…è¦çš„åˆ—
    if "frame_index" not in df.columns:
        raise ValueError(
            f"ç¼ºå°‘ 'frame_index' åˆ—ï¼è¿™æ˜¯å…³é”®å­—æ®µï¼Œç”¨äºå¯¹åº”è§†é¢‘å¸§ã€‚\n"
            f"å¯ç”¨åˆ—: {df.columns.tolist()}"
        )

    # æå–æ•°æ®
    states_raw = np.array([np.array(s) for s in df['state'].tolist()], dtype=np.float32)
    actions_raw = np.array([np.array(a) for a in df['action'].tolist()], dtype=np.float32)
    timestamps = df['timestamp'].values
    frame_indices = df['frame_index'].values.astype(np.int32)  # âœ… é‡è¦ï¼šä½¿ç”¨ frame_index

    # ç¡®ä¿åªå–å‰4ä¸ªå…³èŠ‚ï¼ˆæŒ–æ˜æœºé…ç½®ï¼‰
    states_4d = states_raw[:, :4]
    actions_4d = actions_raw[:, :4]

    print(f"  æ ·æœ¬æ•°: {len(states_4d)}")
    print(f"  æ—¶é—´æˆ³èŒƒå›´: [{timestamps.min():.2f}, {timestamps.max():.2f}]")
    print(f"  å¸§ç´¢å¼•èŒƒå›´: [{frame_indices.min()}, {frame_indices.max()}]")

    # ===== åŠ è½½è§†é¢‘å¸§ =====
    print(f"\nğŸ“¹ åŠ è½½è§†é¢‘æ–‡ä»¶: {video_path}")
    print(f"  åŸå§‹åˆ†è¾¨ç‡: 640x480")

    mp4reader = MP4Reader(
        filepath=str(video_path),
        resolution=(224, 224),
        video_hw=640,
        video_hh=480
    )
    video_frames = mp4reader.read_all_frames()
    mp4reader.release()

    print(f"  è¯»å–å¸§æ•°: {len(video_frames)}")
    print(f"  å¤„ç†ååˆ†è¾¨ç‡: {video_frames.shape}")

    # éªŒè¯ frame_index æœ‰æ•ˆæ€§
    max_frame_idx = frame_indices.max()
    if max_frame_idx >= len(video_frames):
        print(f"âš ï¸ è­¦å‘Š: æœ€å¤§å¸§ç´¢å¼• {max_frame_idx} >= è§†é¢‘å¸§æ•° {len(video_frames)}")
        print(f"   å°†æˆªæ–­åˆ°æœ‰æ•ˆèŒƒå›´")
        valid_mask = frame_indices < len(video_frames)
        states_4d = states_4d[valid_mask]
        actions_4d = actions_4d[valid_mask]
        timestamps = timestamps[valid_mask]
        frame_indices = frame_indices[valid_mask]

    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"  æ ·æœ¬æ•°: {len(states_4d)}")
    print(f"  çŠ¶æ€ç»´åº¦: {states_4d.shape}")
    print(f"  åŠ¨ä½œç»´åº¦: {actions_4d.shape}")
    print(f"  è§†é¢‘å¸§æ•°: {len(video_frames)}")

    data_info = {
        "num_samples": len(states_4d),
        "state_dim": states_4d.shape[1],
        "action_dim": actions_4d.shape[1],
        "timestamps": timestamps,
        "frame_indices": frame_indices,
        "num_video_frames": len(video_frames),
    }

    return states_4d, actions_4d, timestamps, frame_indices, video_frames, data_info


def create_observation_dict(state: np.ndarray, image: np.ndarray) -> dict:
    """
    æ ¹æ®è®­ç»ƒé…ç½®åˆ›å»ºè§‚å¯Ÿå¯¹è±¡

    æ³¨æ„ï¼š
    - âœ… ä½¿ç”¨çœŸå®çš„è§†é¢‘å›¾åƒè€Œéè™šæ‹Ÿå›¾åƒ
    - âœ… ä¸ä½¿ç”¨ prompt å­—æ®µï¼ˆæ¨¡å‹è®­ç»ƒæ—¶æ²¡æœ‰ä½¿ç”¨æ–‡æœ¬é©±åŠ¨ï¼‰
    - æ ¼å¼åº”ä¸ droid_policy.ExcavatorInputs ä¸€è‡´
    """
    obs = {
        "state": state,              # shape (4,) - æŒ–æ˜æœº4ä¸ªå…³èŠ‚
        "image": image,              # shape (224, 224, 3) - çœŸå®è§†é¢‘å¸§
    }
    # âœ… ä¸æ·»åŠ  prompt å­—æ®µ

    return obs


def infer_batch(policy: WebsocketClientPolicy, states: np.ndarray,
                frame_indices: np.ndarray, video_frames: np.ndarray,
                batch_size: int = 1) -> tuple:
    """
    æ‰¹é‡æ¨ç†

    Args:
        policy: WebsocketClientPolicyå®ä¾‹
        states: shape (num_samples, state_dim)
        frame_indices: æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„è§†é¢‘å¸§ç´¢å¼•
        video_frames: æ‰€æœ‰è§†é¢‘å¸§æ•°æ®
        batch_size: æ‰¹å¤§å°ï¼ˆå½“å‰å›ºå®šä¸º1ï¼‰

    Returns:
        predictions: shape (num_samples, 4)
        errors: é”™è¯¯åˆ—è¡¨
    """
    print("\n" + "="*60)
    print("ğŸš€ å¼€å§‹æ¨ç†")
    print("="*60)

    predictions = []
    errors = []

    for i in tqdm(range(len(states)), desc="æ¨ç†è¿›åº¦"):
        try:
            # âœ… ä½¿ç”¨ frame_index è·å–å¯¹åº”çš„è§†é¢‘å¸§
            frame_idx = int(frame_indices[i])
            if frame_idx >= len(video_frames):
                frame_idx = len(video_frames) - 1

            image = video_frames[frame_idx]
            obs = create_observation_dict(states[i], image)
            result = policy.infer(obs)

            # å¤„ç†æ¨ç†è¾“å‡º
            action = None
            if "actions" in result:
                acts = np.array(result["actions"])
                # å¤„ç†ä¸åŒçš„ç»´åº¦æƒ…å†µ
                if acts.ndim == 3:  # (batch, horizon, dim)
                    action = acts[0, 0, :4]
                elif acts.ndim == 2:  # (horizon, dim) æˆ– (batch, dim)
                    if acts.shape[0] == 1:  # (1, dim) - å•batch
                        action = acts[0, :4]
                    else:  # (horizon, dim)
                        action = acts[0, :4]
                elif acts.ndim == 1:  # (dim,)
                    action = acts[:4]

            elif "action" in result:
                acts = np.array(result["action"])
                if acts.ndim == 2:
                    action = acts[0, :4]
                elif acts.ndim == 1:
                    action = acts[:4]

            if action is None:
                action = np.full(4, np.nan, dtype=np.float32)
                errors.append((i, "æ— æ³•æå–action"))
            else:
                action = np.asarray(action, dtype=np.float32)[:4]

            predictions.append(action)

        except Exception as e:
            predictions.append(np.full(4, np.nan, dtype=np.float32))
            errors.append((i, str(e)))
            if i == 0:
                print(f"  âš ï¸ ç¬¬ä¸€ä¸ªé”™è¯¯: {e}")

    predictions_np = np.array(predictions)

    print(f"\nâœ… æ¨ç†å®Œæˆ:")
    print(f"  æˆåŠŸæ ·æœ¬: {np.sum(~np.isnan(predictions_np[:, 0]))}/{len(predictions)}")
    if errors:
        print(f"  å¤±è´¥æ•°: {len(errors)}")
        if len(errors) <= 5:
            for idx, err in errors:
                print(f"    æ ·æœ¬{idx}: {err}")

    return predictions_np, errors


def analyze_and_visualize(states: np.ndarray, true_actions: np.ndarray,
                          predictions: np.ndarray, timestamps: np.ndarray,
                          output_dir: Path):
    """ç”Ÿæˆåˆ†æå’Œå¯è§†åŒ– + è§’åº¦åŒ…è£…çº æ­£"""
    print("\n" + "="*60)
    print("ğŸ“Š ç”Ÿæˆåˆ†æå’Œå¯è§†åŒ–ï¼ˆå«è§’åº¦åŒ…è£…çº æ­£ï¼‰")
    print("="*60)

    output_dir.mkdir(exist_ok=True)

    # è¿‡æ»¤æ‰æ— æ•ˆé¢„æµ‹
    valid_mask = ~np.isnan(predictions[:, 0])
    valid_len = np.sum(valid_mask)

    if valid_len == 0:
        print("âŒ æ‰€æœ‰é¢„æµ‹éƒ½æ— æ•ˆï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
        return

    states_valid = states[valid_mask]
    true_actions_valid = true_actions[valid_mask]
    predictions_valid = predictions[valid_mask]
    timestamps_valid = timestamps[valid_mask]

    # ===== è®¡ç®—åŸå§‹è¯¯å·® =====
    errors_original = true_actions_valid - predictions_valid
    mae_original = np.mean(np.abs(errors_original), axis=0)
    rmse_original = np.sqrt(np.mean(errors_original**2, axis=0))

    # ===== åº”ç”¨è§’åº¦åŒ…è£…çº æ­£ï¼ˆJ4 - å›è½¬å…³èŠ‚ï¼‰=====
    true_actions_wrapped = apply_angle_wrapping(true_actions_valid, dims=[3])
    predictions_wrapped = apply_angle_wrapping(predictions_valid, dims=[3])

    # è®¡ç®—åº”ç”¨è§’åº¦åŒ…è£…åçš„è¯¯å·®
    errors_wrapped = true_actions_wrapped - predictions_wrapped
    mae_wrapped = np.mean(np.abs(errors_wrapped), axis=0)
    rmse_wrapped = np.sqrt(np.mean(errors_wrapped**2, axis=0))

    # è®¡ç®—æ”¹è¿›ç¨‹åº¦
    mae_improvement = (1 - mae_wrapped / np.clip(mae_original, 1e-6, None)) * 100

    # é»˜è®¤ä½¿ç”¨åŒ…è£…åçš„è¯¯å·®ç”¨äºå¯è§†åŒ–
    errors = errors_wrapped
    mae = mae_wrapped
    rmse = rmse_wrapped

    print("\nğŸ“ˆ è§’åº¦åŒ…è£…å¤„ç†ç»“æœï¼ˆJ4 - å›è½¬å…³èŠ‚ï¼‰:")
    print(f"  åŸå§‹ MAE:      {mae_original[3]:.6f} rad")
    print(f"  åŒ…è£…å MAE:    {mae_wrapped[3]:.6f} rad")
    print(f"  æ”¹è¿›ç¨‹åº¦:      {mae_improvement[3]:.1f}%")
    print(f"  å—å½±å“æ ·æœ¬:    {np.sum(np.abs(errors_original[:, 3]) > np.abs(errors_wrapped[:, 3]))}/{len(true_actions_valid)} ")

    joint_names = ['å¤§è‡‚ (Boom)', 'å°è‡‚ (Arm)', 'é“²æ–— (Bucket)', 'å›è½¬ (Swing)']

    # ===== å›¾è¡¨1: æ—¶åºå¯¹æ¯” =====
    fig_ts, axes_ts = plt.subplots(4, 1, figsize=(14, 10), sharex=True)

    for i in range(4):
        ax = axes_ts[i]
        ax.plot(timestamps_valid, true_actions_valid[:, i],
               label='çœŸå®å€¼', color='#1f77b4', linewidth=2, alpha=0.7)
        ax.plot(timestamps_valid, predictions_valid[:, i],
               label='é¢„æµ‹å€¼', color='#ff7f0e', linewidth=1.5, linestyle='--')
        ax.fill_between(timestamps_valid,
                       true_actions_valid[:, i],
                       predictions_valid[:, i],
                       color='gray', alpha=0.2)

        ax.set_ylabel(f'{joint_names[i]}\n(rad)', fontsize=11)
        ax.grid(True, linestyle=':', alpha=0.5)
        ax.text(0.98, 0.95, f'MAE: {mae[i]:.4f}\nRMSE: {rmse[i]:.4f}',
               transform=ax.transAxes, fontsize=9,
               verticalalignment='top', horizontalalignment='right',
               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))

        if i == 0:
            ax.legend(loc='upper left', fontsize=10)
        if i == 3:
            ax.set_xlabel('æ—¶é—´ (ç§’)', fontsize=11)

    fig_ts.suptitle('V3: æ—¶åºå¯¹æ¯” - çœŸå®å€¼ vs é¢„æµ‹å€¼', fontsize=14, fontweight='bold')
    plt.tight_layout()
    fig_ts.savefig(output_dir / 'v3_1_time_series.png', dpi=150, bbox_inches='tight')
    plt.close(fig_ts)

    # ===== å›¾è¡¨2: è¯¯å·®åˆ†æ =====
    fig_err = plt.figure(figsize=(16, 10))
    gs = fig_err.add_gridspec(2, 4, hspace=0.3, wspace=0.3)

    for i in range(4):
        # ä¸Šæ’ï¼šè¯¯å·®éšæ—¶åºå˜åŒ–
        ax_line = fig_err.add_subplot(gs[0, i])
        ax_line.plot(timestamps_valid, errors[:, i], color='#d62728', linewidth=1, alpha=0.7)
        ax_line.axhline(0, color='black', linestyle='-', linewidth=0.8)
        ax_line.axhline(0.05, color='gray', linestyle=':', alpha=0.5, label='Â±0.05')
        ax_line.axhline(-0.05, color='gray', linestyle=':', alpha=0.5)
        ax_line.set_title(f'{joint_names[i]} - é¢„æµ‹è¯¯å·®', fontsize=10)
        ax_line.set_ylim(-0.2, 0.2)
        ax_line.grid(True, alpha=0.3)
        if i == 0:
            ax_line.set_ylabel('è¯¯å·® (True - Pred)', fontsize=9)

        # ä¸‹æ’ï¼šçœŸå®å€¼ vs é¢„æµ‹å€¼æ•£ç‚¹
        ax_scatter = fig_err.add_subplot(gs[1, i])
        ax_scatter.scatter(true_actions_valid[:, i], predictions_valid[:, i],
                         alpha=0.3, s=5, color='purple')
        # å¯¹è§’çº¿
        lims = [
            min(ax_scatter.get_xlim()[0], ax_scatter.get_ylim()[0]),
            max(ax_scatter.get_xlim()[1], ax_scatter.get_ylim()[1]),
        ]
        ax_scatter.plot(lims, lims, 'k-', alpha=0.5, linewidth=1)
        ax_scatter.set_xlabel('çœŸå®å€¼', fontsize=9)
        if i == 0:
            ax_scatter.set_ylabel('é¢„æµ‹å€¼', fontsize=9)
        ax_scatter.set_title(f'{joint_names[i]} - ç›¸å…³æ€§', fontsize=10)
        ax_scatter.grid(True, alpha=0.3)

    fig_err.suptitle('V3: è¯¯å·®æ·±åº¦åˆ†æ - MAE/RMSE/ç›¸å…³æ€§', fontsize=14, fontweight='bold')
    plt.tight_layout()
    fig_err.savefig(output_dir / 'v3_2_error_analysis.png', dpi=150, bbox_inches='tight')
    plt.close(fig_err)

    # ===== å›¾è¡¨3: è¯¯å·®åˆ†å¸ƒ =====
    fig_hist, axes_hist = plt.subplots(1, 4, figsize=(14, 4), sharey=True)

    for i in range(4):
        ax = axes_hist[i]
        ax.hist(errors[:, i], bins=30, color='#d62728', alpha=0.7, edgecolor='black')
        ax.axvline(0, color='black', linestyle='-', linewidth=1)
        ax.set_title(f'{joint_names[i]}', fontsize=10)
        ax.set_xlabel('è¯¯å·®èŒƒå›´ (rad)', fontsize=9)
        ax.grid(True, axis='y', alpha=0.3)
        if i == 0:
            ax.set_ylabel('æ ·æœ¬æ•°é‡', fontsize=9)

    fig_hist.suptitle('V3: è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾', fontsize=14, fontweight='bold')
    plt.tight_layout()
    fig_hist.savefig(output_dir / 'v3_3_error_distribution.png', dpi=150, bbox_inches='tight')
    plt.close(fig_hist)

    # ===== ä¿å­˜æ•°æ® =====
    results_df = pd.DataFrame({
        'timestamp': timestamps_valid,
        'true_J1': true_actions_valid[:, 0], 'pred_J1': predictions_valid[:, 0],
        'true_J2': true_actions_valid[:, 1], 'pred_J2': predictions_valid[:, 1],
        'true_J3': true_actions_valid[:, 2], 'pred_J3': predictions_valid[:, 2],
        'true_J4': true_actions_valid[:, 3], 'pred_J4': predictions_valid[:, 3],
    })
    results_df.to_csv(output_dir / 'v3_predictions.csv', index=False)

    # ä¿å­˜æ±‡æ€»ç»Ÿè®¡ - åŒ…å«åŸå§‹å’ŒåŒ…è£…åçš„å¯¹æ¯”
    stats_summary = {
        "æ€»æ ·æœ¬æ•°": len(predictions),
        "æœ‰æ•ˆæ ·æœ¬æ•°": int(valid_len),
        "æ— æ•ˆæ ·æœ¬æ•°": len(predictions) - int(valid_len),
        "å…³èŠ‚": joint_names,
        "åŸå§‹ç»“æœ": {
            "MAE": mae_original.tolist(),
            "RMSE": rmse_original.tolist(),
        },
        "è§’åº¦åŒ…è£…åç»“æœ": {
            "MAE": mae_wrapped.tolist(),
            "RMSE": rmse_wrapped.tolist(),
        },
        "æ”¹è¿›ç¨‹åº¦ï¼ˆ%ï¼‰": mae_improvement.tolist(),
        "å¤‡æ³¨": "è§’åº¦åŒ…è£…åº”ç”¨äº J4ï¼ˆå›è½¬å…³èŠ‚ï¼‰ï¼Œä½¿ç”¨ atan2(sin(Î¸), cos(Î¸)) å°†è§’åº¦è§„èŒƒåŒ–åˆ° [-Ï€, Ï€]"
    }

    with open(output_dir / 'v3_stats.json', 'w') as f:
        json.dump(stats_summary, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… å¯è§†åŒ–å®Œæˆ:")
    print(f"  è¾“å‡ºç›®å½•: {output_dir.absolute()}")
    print(f"  ç”Ÿæˆæ–‡ä»¶:")
    print(f"    - v3_1_time_series.png (æ—¶åºå¯¹æ¯”)")
    print(f"    - v3_2_error_analysis.png (è¯¯å·®åˆ†æ)")
    print(f"    - v3_3_error_distribution.png (è¯¯å·®åˆ†å¸ƒ)")
    print(f"    - v3_predictions.csv (åŸå§‹æ•°æ®)")
    print(f"    - v3_stats.json (ç»Ÿè®¡æ±‡æ€» - å«è§’åº¦åŒ…è£…å¯¹æ¯”)")

    print(f"\nğŸ“ˆ è¯¯å·®ç»Ÿè®¡æ±‡æ€»ï¼ˆåº”ç”¨è§’åº¦åŒ…è£…åï¼‰:")
    for i, name in enumerate(joint_names):
        print(f"  {name}:")
        print(f"    åŸå§‹ MAE:    {mae_original[i]:.6f} rad")
        print(f"    åŒ…è£…å MAE:  {mae_wrapped[i]:.6f} rad")
        print(f"    æ”¹è¿›:        {mae_improvement[i]:+.1f}%")
        print(f"    åŒ…è£…å RMSE: {rmse_wrapped[i]:.6f} rad")


# ==========================================
# ä¸»ç¨‹åº
# ==========================================

def main():
    configure_fonts()

    print("\n" + "="*60)
    print("ğŸ”§ æŒ–æ˜æœºæ¨ç†ç³»ç»Ÿ V3 - ä¿®å¤ç‰ˆï¼ˆå«çœŸå®è§†é¢‘å¸§ï¼‰")
    print("="*60)
    print(f"\né…ç½®:")
    print(f"  æ•°æ®é›†: {CONFIG['data_path']}")
    print(f"  æ¨ç†æœåŠ¡: {CONFIG['host']}:{CONFIG['port']}")

    try:
        # 1. åŠ è½½æ•°æ®
        states, actions, timestamps, frame_indices, video_frames, data_info = load_data_with_validation(
            CONFIG["data_path"],
            CONFIG["num_samples"]
        )

        # 2. è¿æ¥æ¨ç†æœåŠ¡
        print("\n" + "="*60)
        print("ğŸ”Œ è¿æ¥æ¨ç†æœåŠ¡")
        print("="*60)
        print(f"è¿æ¥åˆ° {CONFIG['host']}:{CONFIG['port']}...")

        policy = WebsocketClientPolicy(host=CONFIG['host'], port=CONFIG['port'])
        print("âœ… è¿æ¥æˆåŠŸ")

        # 3. æ‰§è¡Œæ¨ç†
        predictions, errors = infer_batch(
            policy, states, frame_indices, video_frames
        )

        # 4. åˆ†æå’Œå¯è§†åŒ–
        analyze_and_visualize(
            states, actions, predictions, timestamps,
            CONFIG["output_dir"]
        )

        print("\n" + "="*60)
        print("âœ… æ¨ç†å®Œæˆï¼")
        print("="*60)

    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, force=True)
    main()
